{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a795ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31dca13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d3b778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b7ab65ebf10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "tool_node = BasicToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c72a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"ollama:llama3.2\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61861227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b7ab65ebf10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883467d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b7ab65ebf10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51a40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62435922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: {\"query\": \"Who is tavily?\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://medium.com/codex/tavily-the-api-powered-alternative-to-perplexity-edfdc6814b39\", \"title\": \"Tavily \\u2014 The API-powered Alternative to Perplexity? | by AI Rabbit\", \"content\": \"In simple terms, Tavily is a search service (like Serper or serpapi) with one big advantage: it is built from the ground up for LLM search. Put plainly, you can just ask a question and it can search the internet for you, then answer that specific question. Best of all, it\\u2019s entirely accessible via an API.\\n\\nCreate an account to read the full story.\\n-----------------------------------------\\n\\nThe author made this story available to Medium members only. [...] And here is where Tavily steps in. If you haven\\u2019t heard of them, they\\u2019re the driving force behind the open source research gpt.\\n\\n> With GPT Researcher, you can do exactly what you would expect: AI-powered research using facts from the internet or even on-premise documents, powered by LLMs. It has become incredibly powerful. It\\u2019s worth taking a look at.\\n\\nSo what is Tavily about?\\n------------------------\", \"score\": 0.83932644, \"raw_content\": null}, {\"url\": \"https://docs.tavily.com/documentation/about\", \"title\": \"About - Tavily Docs\", \"content\": \"Tavily is a search engine optimized for LLMs, aimed at efficient, quick and persistent search results. Unlike other search APIs such as Serp or Google, Tavily focuses on optimizing search for AI developers and autonomous AI agents. We take care of all the burden of searching, scraping, filtering and extracting the most relevant information from online sources. All in a single API call!\\n\\nTo try the API in action, you can now use our hosted version on our API Playground. [...] Looking for a step-by-step tutorial to get started in under 5 minutes? Head to our Quickstart guide and start coding!\\n\\n## \\u200b Who are we?\\n\\nWe\\u2019re a team of AI researchers and developers passionate about helping you build the next generation of AI assistants.\\nOur mission is to empower individuals and organizations with accurate, unbiased, and factual information.\\n\\n## \\u200b What is the Tavily Search Engine?\", \"score\": 0.8156003, \"raw_content\": null}], \"response_time\": 1.37}\n",
      "Assistant: Tavily is a search engine optimized for Large Language Models (LLMs), designed to provide efficient and quick search results. It was created by a team of AI researchers and developers who aim to empower individuals and organizations with accurate, unbiased, and factual information. Tavily focuses on optimizing search for AI developers and autonomous AI agents, taking care of the burden of searching, scraping, filtering, and extracting relevant information from online sources in a single API call.\n",
      "Assistant: \n",
      "Assistant: {\"query\": \"operation sindhoor\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.pib.gov.in/PressReleasePage.aspx?PRID=2129453\", \"title\": \"Operation SINDOOR: Forging One Force - PIB\", \"content\": \"In an age of multi-domain warfare, where threats evolve faster than borders shift, India's national security architecture has demonstrated the strength of jointness and strategic foresight. Operation SINDOOR, initiated on May 7, 2025, in the aftermath of the Pahalgam terror attack, which claimed the lives of 26 innocent civilians showcased a calibrated, tri-services response that embodied precision, professionalism, and purpose. Operation SINDOOR was conceived as a punitive and targeted [...] In an age of multi-domain warfare, where threats evolve faster than borders shift, India's national security architecture has demonstrated the strength of jointness and strategic foresight. Operation SINDOOR, initiated on May 7, 2025, in the aftermath of the Pahalgam terror attack, which claimed the lives of 26 innocent civilians showcased a calibrated, tri-services response that embodied precision, professionalism, and purpose. Operation SINDOOR was conceived as a punitive and targeted [...] purpose.Operation SINDOOR was conceived as a punitive and targeted campaign todismantle the terror infrastructureacross theLine of Controland deeper inside Pakistan.Multi-agency intelligenceprovided confirmation ofninemajor camps that were eventually targeted in the operation. India\\u2019s retaliatory action was based onmeticulous planningand anintelligence-led approach, which ensured that the operations were conducted withminimal collateral damage. Operational ethics were central to the mission,\", \"score\": 0.8473754, \"raw_content\": null}, {\"url\": \"https://www.cgiistanbul.gov.in/section/news/summary-of-operation-sindoor/\", \"title\": \"Summary of Operation SINDOOR - News\", \"content\": \"1.   Operation Sindoor is a principle-driven military response underpinned by strategic restraint. It was in response to a barbaric terrorist attack on innocent tourists which originated from Pakistan. India had a right to response which it did, in a responsible, restrained, measured and a non-escalatory manner.\\n\\nImage 6: voters\\n\\nImage 7: ibef\\n\\nImage 8: iccr\\n\\nImage 9: Indiandiplomacy\\n\\nImage 10: Everything MEA on your phone\\n\\nImage 11: GEM India Portal\\n\\nImage 12: AI India\", \"score\": 0.8437023, \"raw_content\": null}], \"response_time\": 2.08}\n",
      "Assistant: Operation SINDOOR was a military operation conducted by the Indian Armed Forces in response to a terrorist attack on innocent tourists in Pahalgam, Jammu and Kashmir. The operation was initiated on May 7, 2025, and was characterized by precision, professionalism, and purpose.\n",
      "\n",
      "The operation was conceived as a punitive and targeted campaign to dismantle terror infrastructure across the Line of Control (LoC) and deeper inside Pakistan. India's retaliatory action was based on meticulous planning and an intelligence-led approach, which ensured that the operations were conducted with minimal collateral damage.\n",
      "\n",
      "Operational ethics were central to the mission, and India's response was described as a principle-driven military response underpinned by strategic restraint. The operation was seen as a responsible, restrained, measured, and non-escalatory manner.\n",
      "\n",
      "Sources:\n",
      "\n",
      "* Press Information Bureau (PIB) - \"Operation SINDOOR: Forging One Force\"\n",
      "* CGI Istanbul - \"Summary of Operation SINDOOR\"\n",
      "\n",
      "Note: The information provided is based on the tool call response and may not be up-to-date or exhaustive.\n",
      "User: What do you know about LangGraph?\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6488aa",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
